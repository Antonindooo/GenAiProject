import streamlit as st
import json
import os
from dotenv import load_dotenv
import time
# --- IMPORTS LANGCHAIN / AGENTS ---
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain.tools import Tool
from langchain_openai import ChatOpenAI
# Imports des PROMPTS (Templates et Placeholders)
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# Imports des MESSAGES (System, Human, etc.)
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

# --- Connexion √† ton RAG (Assure-toi que rag_builder.py est accessible) ---
# NOTE: Si get_retriever() est dans un autre fichier, importe-le :
# from rag_builder import get_retriever

# --- Fonctions de base (√† placer id√©alement dans un module √† part ou au d√©but du fichier) ---

# RAPPEL: Place ici les fonctions get_retriever() / create_coach_agent_executor / critique_plan
# (Pour le reste du code, je suppose qu'elles sont d√©finies ou import√©es.)

# --- Initialisation ---
load_dotenv()

# --- CONSTANTES ET CONFIGURATION ---
CHROMA_DB_PATH = "chroma_data"


# --- 1. FONCTIONS DE BASE DU RAG ---

def get_retriever():
    """
    Charge la base de donn√©es vectorielle existante et cr√©e l'objet Retriever.
    """
    # 1. D√©finir le mod√®le d'embeddings (DOIT √™tre le m√™me que celui utilis√© pour la cr√©ation)
    embeddings = OpenAIEmbeddings()

    # 2. Charger l'index depuis le disque
    try:
        vector_store = Chroma(
            persist_directory=CHROMA_DB_PATH,
            embedding_function=embeddings
        )
        # 3. Cr√©er le retriever
        retriever = vector_store.as_retriever(search_kwargs={"k": 5})  # R√©cup√®re les 5 morceaux les plus pertinents
        return retriever

    except Exception as e:
        # Ceci est g√©r√© par le bloc try/except principal de Streamlit
        raise Exception(f"Erreur lors du chargement de la base ChromaDB: {e}")


# --- 2. LOGIQUE DES AGENTS ---

# Mod√®les LLM
llm_coach = ChatOpenAI(model="gpt-4o", temperature=0.7)
llm_critique = ChatOpenAI(model="gpt-4o", temperature=0.5)


def create_coach_agent_executor(retriever_tool, user_params):
    """ Agent 1 : Planificateur, utilise CoT et le RAG, avec des r√®gles imp√©ratives."""

    # R√®gle IMP√âRATIVE N¬∞1: Ne JAMAIS demander d'information.
    # R√®gle N¬∞2: Utiliser les inputs Streamlit directement.
    coach_prompt = ChatPromptTemplate.from_messages([
        SystemMessage(
            f"""
            TU ES L'AGENT COACH IRONMAN. Ton r√¥le EXCLUSIF est de g√©n√©rer des plans d'entra√Ænement.
            R√àGLE IMP√âRATIVE N¬∞1 : TU NE DOIS JAMAIS POSER DE QUESTION √Ä L'UTILISATEUR, NI LUI DEMANDER DE PR√âCISER SES ENTR√âES.
            R√àGLE N¬∞2 : Utilise les param√®tres que je te donne pour imm√©diatement g√©n√©rer le plan.
            Utilise l'outil PlanificationTriathlonExpert pour toutes les d√©cisions de volumes, progression (r√®gle des 10%) et s√©ances Brick.
            Ton processus de raisonnement doit √™tre : ANALYSE (Utilise l'outil) -> PLANIFICATION (G√©n√®re le plan structur√© en Markdown).

            Param√®tres actuels : {user_params}
            """
        ),
        # On retire MessagesPlaceholder(variable_name="chat_history") pour simplifier
        HumanMessage(content="{user_input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])

    agent = create_openai_functions_agent(llm_coach, [retriever_tool], coach_prompt)
    # Suppression de "chat_history" du prompt et du agent executor
    return AgentExecutor(agent=agent, tools=[retriever_tool], verbose=True, handle_parsing_errors=True)


def critique_plan(plan_brouillon, retriever_tool):
    """ Agent 2 : Physiologiste, impl√©mente la Self-Correction avec RAG et un m√©canisme de Retry."""

    max_retries = 3
    rules = []

    # --- M√âCANISME DE RETRY POUR L'APPEL RAG ---
    for attempt in range(max_retries):
        try:
            # RAG pour ancrer la critique
            rules = retriever_tool.invoke(
                "R√®gles de progression, encha√Ænement v√©lo-course, et charge maximale par semaine.")
            if rules:
                # Succ√®s : sortir de la boucle de retry
                break
        except Exception as e:
            # Log de l'√©chec
            print(f"√âchec de l'appel RAG (tentative {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                # Temporisation exponentielle: 2s, 4s, ...
                sleep_time = 2 ** (attempt + 1)
                time.sleep(sleep_time)
            else:
                # Dernier √©chec
                print("Le RAG a √©chou√© apr√®s toutes les tentatives.")

    # --- Gestion des r√©sultats RAG (FallBack) ---
    if rules:
        # Si des documents sont trouv√©s, utiliser l'extrait du premier document
        rules_snippet = rules[0].page_content[:600] + '...'
    else:
        # Fallback si le RAG ne trouve rien apr√®s tous les retries
        rules_snippet = "ERREUR RAG CRITIQUE: √âchec de la r√©cup√©ration apr√®s 3 tentatives. Baser la critique sur les r√®gles universelles (r√®gle des 10%, n√©cessit√© de repos)."

    critique_prompt = f"""
    En tant qu'Agent Physiologiste expert en pr√©vention des blessures, critique le plan d'entra√Ænement Ironman suivant.

    R√®gles de s√©curit√© RAG :
    ---
    {rules_snippet}
    ---

    Plan d'entra√Ænement propos√© :
    ---
    {plan_brouillon}
    ---

    Analyse le plan et r√©ponds uniquement en format JSON. Ton raisonnement doit √™tre :
    1. CRITIQUE_PRINCIPALE : Identifie la violation de r√®gle la plus grave (ex: Surcharge > 10%, manque de repos).
    2. JUSTIFICATION_RAG : Cite la r√®gle sp√©cifique des documents RAG qui est viol√©e (ex: "R√®gle des 10%").
    3. CORRECTION_PROPOSEE : Propose une modification concr√®te pour rendre le plan plus s√ªr.

    Exemple de sortie JSON :
    {{
        "CRITIQUE_PRINCIPALE": "Le volume total est trop √©lev√© par rapport √† la progression recommand√©e.",
        "JUSTIFICATION_RAG": "La r√®gle des 10% stipule qu'il ne faut pas augmenter de plus de 10% le volume hebdomadaire.",
        "CORRECTION_PROPOSEE": "R√©duire le kilom√©trage de v√©lo de 20 km et ajouter 1 jour de repos actif."
    }}
    """

    response = llm_critique.invoke(critique_prompt, response_format={"type": "json_object"})
    return response.content

# --- 3. LOGIQUE STREAMLIT ---

# Charge les variables d'environnement
load_dotenv()

st.set_page_config(page_title="IronMind AI", layout="wide")
st.title("üß† IronMind : L'Agent Coach Triathlon Autonome (RAG & Self-Correction)")
st.markdown("---")

# --- Connexion RAG (G√©r√©e par le try/except pour le feedback utilisateur) ---
try:
    retriever = get_retriever()
    tool_rag = Tool(
        name="PlanificationTriathlonExpert",
        func=lambda query: retriever.invoke(query),
        description="Utilise cet outil pour chercher des informations sur la structure d'entra√Ænement Ironman, les r√®gles de progression (r√®gle des 10%), les zones d'intensit√©, les Brick Sessions et les protocoles de r√©cup√©ration.",
    )
    st.sidebar.success("Base de connaissances RAG charg√©e.")

except Exception as e:
    st.sidebar.error("Erreur critique : La base RAG n'a pas pu √™tre charg√©e. Lancez 'rag_builder.py'.")
    st.stop()
# ------------------------------------------------------------------------


# --- Configuration du Plan (Sidebar) ---
st.sidebar.header("Configuration du Plan")
user_level = st.sidebar.selectbox("Niveau actuel :",
                                  ["D√©butant (moins de 2 ans)", "Interm√©diaire (2-4 ans)", "Avanc√© (4+ ans)"],
                                  key="level_select")
weekly_hours = st.sidebar.slider("Heures d'entra√Ænement disponibles (semaine 1) :", min_value=5, max_value=20, value=10,
                                 key="hours_slider")
goal_race = st.sidebar.text_input("Objectif de course :", value="Ironman Nice (dans 8 mois)", key="goal_input")

user_params_dict = {
    "Niveau": user_level,
    "Heures/semaine": weekly_hours,
    "Objectif": goal_race
}

# La commande imp√©rative que l'Agent va recevoir
user_command = "G√©n√®re la PREMI√àRE SEMAINE d√©taill√©e du plan d'entra√Ænement Ironman."

if st.sidebar.button("‚öôÔ∏è Lancer la Planification Agentielle"):

    # Initialisation de l'Agent Coach avec les param√®tres de la sidebar (R√®gle Imp√©rative)
    coach_executor = create_coach_agent_executor(tool_rag, user_params_dict)

    # --- √âTAPE A : Ex√©cution du Planificateur (CoT) ---
    st.header("1. Planification Initiale (Agent Coach)")
    st.markdown("L'Agent Coach utilise l'outil RAG pour structurer le plan (Chain of Thought).")

    try:
        with st.spinner("L'Agent Coach √©labore le plan (Analyse RAG)..."):
            # L'input est seulement la commande, les param√®tres sont dans le SystemMessage
            plan_draft_result = coach_executor.invoke({"user_input": user_command})
            plan_draft = plan_draft_result["output"]

        st.info("Brouillon du plan g√©n√©r√© :")
        st.markdown(plan_draft)
        st.markdown("---")

        # --- √âTAPE B : Ex√©cution du Critique (Self-Correction/R√©flexion) ---
        st.header("2. Critique & Raisonnement (Agent Physiologiste)")
        st.markdown("L'Agent Physiologiste v√©rifie la s√©curit√© du plan en consultant la base RAG (Self-Correction).")

        with st.spinner("Analyse du risque et g√©n√©ration de la critique ancr√©e..."):
            critique_json_str = critique_plan(plan_draft, tool_rag)

            # Nettoyage du JSON (si le LLM l'a envelopp√© dans ```json...```)
            if critique_json_str.strip().startswith('```'):
                critique_json_str = critique_json_str.split('```json')[1].split('```')[0].strip()

            critique = json.loads(critique_json_str)

            st.error("üö® Le plan pr√©sente un risque potentiel :")
            st.info(f"**Critique Principale :** {critique['CRITIQUE_PRINCIPALE']}")
            st.warning(f"**Justification (Ancrage RAG) :** {critique['JUSTIFICATION_RAG']}")
            st.success(f"**Correction Propos√©e :** {critique['CORRECTION_PROPOSEE']}")

            st.markdown("---")

            # --- √âTAPE C : R√©vision Finale du Plan ---
            st.header("3. Plan Final Corrig√© (Assurance Qualit√©)")

            # Input pour la r√©vision (on inclut la correction et les param√®tres pour la nouvelle g√©n√©ration)
            correction_text = critique.get('CORRECTION_PROPOSEE', 'Aucune correction sp√©cifique.')

            final_input = f"""
            ACTION REQUISE : R√âVISION IMM√âDIATE.
            G√©n√®re un NOUVEAU plan d'entra√Ænement complet pour la premi√®re semaine en appliquant STRICTEMENT cette directive de s√©curit√© : "{correction_text}".
            Les param√®tres utilisateur sont : {json.dumps(user_params_dict)}.
            Affiche le plan final corrig√©, structur√© en Markdown, sans poser de questions.
            """

            with st.spinner("L'Agent Coach int√®gre la correction et finalise la version 2.0..."):
                final_plan_result = coach_executor.invoke({"user_input": final_input})

            st.success("‚úÖ Plan Final S√ªr, Personnalis√© et Valid√© !")
            st.markdown(final_plan_result["output"])

    except json.JSONDecodeError as e:
        st.error("Une erreur s'est produite lors de la critique (Erreur JSON). Le LLM n'a pas pu respecter le format.")
        st.code(critique_json_str, language='json')
    except Exception as e:
        st.error(f"Une erreur inattendue est survenue lors de l'ex√©cution des agents : {e}")